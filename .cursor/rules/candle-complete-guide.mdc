---
description: Complete Candle ML framework guide - comprehensive best practices for beginners
alwaysApply: false
---
# Candle ML Framework - Полное руководство для джунов

## Обзор фреймворка

Candle — это революционный ML фреймворк для Rust от Hugging Face, который сочетает знакомый PyTorch-подобный синтаксис с производительностью и безопасностью Rust. Основные преимущества:

- **Без Python runtime** в production — компактные бинарные файлы
- **Безопасность типов** — compile-time проверки размерностей тензоров
- **Интеграция с Hugging Face** — поддержка safetensors и токенизаторов
- **Serverless-ready** — идеально для развертывания без зависимостей
- **Высокая производительность** — нативная скорость Rust + GPU ускорение

## Быстрый старт

### 1. Настройка проекта

```toml
# Cargo.toml
[dependencies]
candle-core = "0.9"
candle-nn = "0.9"
candle-transformers = "0.9"
hf-hub = "0.4"

# Выберите один бэкенд:
candle-core = { version = "0.9", features = ["cuda"] }    # CUDA GPU
candle-core = { version = "0.9", features = ["metal"] }   # Metal GPU (macOS)
candle-core = { version = "0.9", features = [] }          # CPU only
```

### 2. Первая программа

```rust
use candle_core::{Tensor, Device, DType};

fn main() -> Result<(), Box<dyn std::error::Error>> {
    let device = Device::Cpu;

    // Создаем тензоры
    let a = Tensor::randn(0f32, 1f32, (2, 3), &device)?;
    let b = Tensor::randn(0f32, 1f32, (3, 4), &device)?;

    // Матричное умножение
    let c = a.matmul(&b)?;

    println!("Результат: {:?}", c.shape());
    Ok(())
}
```

## Основные концепции

### Тензоры и операции

```rust
use candle_core::{Tensor, Device, DType};

// Создание тензоров
let device = Device::Cpu;
let tensor = Tensor::zeros((2, 3), DType::F32, &device)?;

// Операции с тензорами
let a = Tensor::ones((2, 2), DType::F32, &device)?;
let b = Tensor::ones((2, 2), DType::F32, &device)?;
let sum = &a + &b;  // Создает новый тензор

// Индексирование
let slice = tensor.i((.., ..2))?;  // Все строки, первые 2 колонки

// Reshape
let reshaped = tensor.reshape((3, 2))?;
```

### Управление устройствами

```rust
// CPU устройство
let device = Device::Cpu;

// CUDA устройство (требует feature "cuda")
let device = Device::new_cuda(0)?;  // GPU 0

// Metal устройство (требует feature "metal", только macOS)
let device = Device::new_metal(0)?;

// Перенос тензоров между устройствами
let cpu_tensor = Tensor::ones((2, 2), DType::F32, &Device::Cpu)?;
let gpu_tensor = cpu_tensor.to_device(&device)?;
```

## Нейронные сети

### Создание слоев

```rust
use candle_nn::{Linear, LayerNorm, Dropout, VarBuilder};

// Линейный слой
let linear = Linear::new(10, 5, &device)?;

// Layer Normalization
let layer_norm = LayerNorm::new(768, 1e-5, &device)?;

// Dropout
let mut dropout = Dropout::new(0.1);
dropout.set_training(true);  // Для обучения
```

### Простая модель

```rust
use candle_nn::{Linear, ReLU, Sequential};

struct SimpleModel {
    layers: Sequential,
}

impl SimpleModel {
    fn new(input_size: usize, hidden_size: usize, output_size: usize, device: &Device) -> Result<Self> {
        let layers = Sequential::new(vec![
            Box::new(Linear::new(input_size, hidden_size, device)?),
            Box::new(ReLU),
            Box::new(Linear::new(hidden_size, output_size, device)?),
        ]);

        Ok(Self { layers })
    }

    fn forward(&self, input: &Tensor) -> Result<Tensor> {
        self.layers.forward(input)
    }
}
```

## Интеграция с Hugging Face

### Загрузка моделей

```rust
use hf_hub::{api, api::Repo};
use candle_transformers::models::llama::{Llama, LlamaConfig};

async fn load_model_from_hub(model_id: &str, device: &Device) -> Result<Llama> {
    let api = api::HfApi::new()?;
    let repo = Repo::with_revision(model_id.to_string(), "main".to_string());

    // Загружаем конфигурацию
    let config_filename = api.get(&repo, "config.json").await?;
    let config: LlamaConfig = serde_json::from_slice(&config_filename)?;

    // Загружаем веса
    let weights_filename = api.get(&repo, "model.safetensors").await?;
    let weights = candle_core::safetensors::load_buffer(&weights_filename, device)?;

    // Создаем модель
    Llama::load(&weights, &config, device)
}
```

### Работа с токенизаторами

```rust
use tokenizers::tokenizer::Tokenizer;

struct HFTokenizer {
    tokenizer: Tokenizer,
    device: Device,
}

impl HFTokenizer {
    async fn from_hub(model_id: &str, device: Device) -> Result<Self> {
        let api = api::HfApi::new()?;
        let repo = Repo::with_revision(model_id.to_string(), "main".to_string());

        let tokenizer_data = api.get(&repo, "tokenizer.json").await?;
        let tokenizer = Tokenizer::from_bytes(&tokenizer_data)?;

        Ok(Self { tokenizer, device })
    }

    fn encode(&self, text: &str) -> Result<Tensor> {
        let encoding = self.tokenizer.encode(text, true)?;
        let tokens = encoding.get_ids();
        Tensor::new(tokens, &self.device)
    }

    fn decode(&self, tokens: &Tensor) -> Result<String> {
        let token_ids: Vec<u32> = tokens.to_vec1()?;
        self.tokenizer.decode(&token_ids, true)
    }
}
```

## Оптимизация производительности

### GPU оптимизация

```rust
// Создавайте устройство один раз и переиспользуйте
let device = Device::new_cuda(0)?;

// Группируйте операции на GPU
let a = Tensor::randn(0f32, 1f32, (1000, 1000), &device)?;
let b = Tensor::randn(0f32, 1f32, (1000, 1000), &device)?;
let c = a.matmul(&b)?;  // Все операции на GPU
let d = c.relu()?;      // Продолжаем на GPU

// Батчинг для оптимальной производительности
let batch_size = 32;  // Кратно warp size для NVIDIA GPU
let batch_inputs = Tensor::stack(&inputs, 0)?;
let batch_results = batch_inputs.matmul(&weights)?;
```

### Профилирование

```rust
use std::time::Instant;

fn benchmark_operation() -> Result<()> {
    let device = Device::new_cuda(0)?;
    let tensor = Tensor::randn(0f32, 1f32, (1000, 1000), &device)?;

    // Разогрев GPU
    for _ in 0..10 {
        let _ = tensor.matmul(&tensor)?;
    }

    let start = Instant::now();
    let result = tensor.matmul(&tensor)?;
    device.synchronize()?;  // Синхронизация для точного измерения
    let duration = start.elapsed();

    println!("Операция заняла: {:?}", duration);
    Ok(())
}
```

## Архитектурные паттерны

### Trait-based архитектура

```rust
use candle_core::{Tensor, Result, Device};

pub trait Model {
    type Config;

    fn new(config: Self::Config, device: &Device) -> Result<Self>
    where
        Self: Sized;

    fn forward(&self, input: &Tensor) -> Result<Tensor>;
    fn num_parameters(&self) -> usize;
    fn device(&self) -> &Device;
}

pub trait TrainableModel: Model {
    fn parameters(&self) -> Vec<&Tensor>;
    fn update_parameters(&mut self, gradients: &[Tensor]) -> Result<()>;
}
```

### Builder pattern

```rust
#[derive(Debug, Clone)]
pub struct TransformerConfig {
    pub vocab_size: usize,
    pub hidden_size: usize,
    pub num_attention_heads: usize,
    pub num_hidden_layers: usize,
}

pub struct TransformerBuilder {
    config: TransformerConfig,
}

impl TransformerBuilder {
    pub fn new() -> Self {
        Self {
            config: TransformerConfig::default(),
        }
    }

    pub fn vocab_size(mut self, size: usize) -> Self {
        self.config.vocab_size = size;
        self
    }

    pub fn hidden_size(mut self, size: usize) -> Self {
        self.config.hidden_size = size;
        self
    }

    pub fn build(self, device: &Device) -> Result<Transformer> {
        Transformer::new(self.config, device)
    }
}
```

## Тестирование

### Unit тесты

```rust
#[cfg(test)]
mod tests {
    use super::*;
    use approx::assert_abs_diff_eq;

    #[test]
    fn test_tensor_operations() {
        let device = Device::Cpu;
        let a = Tensor::ones((2, 2), DType::F32, &device).unwrap();
        let b = Tensor::ones((2, 2), DType::F32, &device).unwrap();

        let sum = (&a + &b).unwrap();
        let expected = Tensor::from_slice(&[2.0, 2.0, 2.0, 2.0], (2, 2), &device).unwrap();

        assert_tensor_eq(&sum, &expected, 1e-6);
    }

    fn assert_tensor_eq(a: &Tensor, b: &Tensor, tolerance: f32) {
        assert_eq!(a.shape(), b.shape());
        let a_data: Vec<f32> = a.to_vec1().unwrap();
        let b_data: Vec<f32> = b.to_vec1().unwrap();

        for (a_val, b_val) in a_data.iter().zip(b_data.iter()) {
            assert_abs_diff_eq!(a_val, b_val, epsilon = tolerance);
        }
    }
}
```

### Property-based тесты

```rust
use proptest::prelude::*;

proptest! {
    #[test]
    fn test_tensor_addition_commutativity(
        shape in (1..10usize).prop_flat_map(|s| (s, s)),
        values1 in prop::collection::vec(-10.0f32..10.0, 1..100),
        values2 in prop::collection::vec(-10.0f32..10.0, 1..100)
    ) {
        let device = Device::Cpu;
        let size = shape.0 * shape.1;

        if values1.len() >= size && values2.len() >= size {
            let tensor1 = Tensor::from_slice(&values1[..size], shape, &device).unwrap();
            let tensor2 = Tensor::from_slice(&values2[..size], shape, &device).unwrap();

            let result1 = (&tensor1 + &tensor2).unwrap();
            let result2 = (&tensor2 + &tensor1).unwrap();

            assert_tensor_eq(&result1, &result2, 1e-6);
        }
    }
}
```

## Обработка ошибок

### Custom error types

```rust
use thiserror::Error;

#[derive(Error, Debug)]
pub enum ModelError {
    #[error("Ошибка устройства: {0}")]
    DeviceError(String),

    #[error("Ошибка размерности тензора: ожидалось {expected}, получено {actual}")]
    DimensionMismatch { expected: String, actual: String },

    #[error("Ошибка инициализации модели: {0}")]
    InitializationError(String),
}

impl From<candle_core::Error> for ModelError {
    fn from(err: candle_core::Error) -> Self {
        ModelError::DeviceError(err.to_string())
    }
}

pub type ModelResult<T> = Result<T, ModelError>;
```

## Лучшие практики

### 1. Всегда указывайте устройства явно

```rust
// Плохо
let tensor = Tensor::zeros((2, 2), DType::F32, &Device::Cpu)?;

// Хорошо
let device = Device::Cpu;  // Или Device::new_cuda(0)?
let tensor = Tensor::zeros((2, 2), DType::F32, &device)?;
```

### 2. Используйте осмысленные имена переменных

```rust
// Плохо
let t1 = Tensor::ones((10, 20), DType::F32, &device)?;
let t2 = t1.matmul(&t1)?;

// Хорошо
let input_features = Tensor::ones((batch_size, feature_dim), DType::F32, &device)?;
let hidden_layer = input_features.matmul(&weight_matrix)?;
```

### 3. Группируйте операции на одном устройстве

```rust
// Плохо - много переносов между устройствами
let cpu_tensor = Tensor::ones((2, 2), DType::F32, &Device::Cpu)?;
let gpu_tensor = cpu_tensor.to_device(&gpu_device)?;
let result = gpu_tensor.matmul(&gpu_tensor)?;
let final_result = result.to_device(&Device::Cpu)?;

// Хорошо - минимум переносов
let gpu_tensor = Tensor::ones((2, 2), DType::F32, &gpu_device)?;
let result = gpu_tensor.matmul(&gpu_tensor)?;
// Переносим только финальный результат
```

### 4. Проверяйте размерности перед операциями

```rust
fn safe_matmul(a: &Tensor, b: &Tensor) -> Result<Tensor> {
    if a.dim(1) != b.dim(0) {
        return Err(candle_core::Error::Msg(format!(
            "Несовместимые размерности: {} @ {}",
            a.shape(), b.shape()
        )));
    }
    a.matmul(b)
}
```

### 5. Используйте scoped блоки для управления памятью

```rust
// Используйте scoped блоки для автоматического освобождения памяти
{
    let large_tensor = Tensor::randn(0f32, 1f32, (1000, 1000), &device)?;
    let result = large_tensor.matmul(&large_tensor)?;
    // Память автоматически освобождается здесь
}
```

## Типичные ошибки и их решения

### 1. Несовместимые размерности

```rust
// ОШИБКА: Несовместимые размерности
let a = Tensor::ones((2, 3), DType::F32, &device)?;
let b = Tensor::ones((4, 5), DType::F32, &device)?;
// let c = a.matmul(&b)?;  // ОШИБКА!

// РЕШЕНИЕ: Проверьте размерности
if a.dim(1) == b.dim(0) {
    let c = a.matmul(&b)?;
}
```

### 2. Move после использования

```rust
// ОШИБКА: Move после использования
let tensor = Tensor::ones((2, 2), DType::F32, &device)?;
let result = tensor.matmul(&tensor)?;
// println!("{:?}", tensor.shape());  // ОШИБКА! tensor был moved

// РЕШЕНИЕ: Используйте borrowing
let tensor = Tensor::ones((2, 2), DType::F32, &device)?;
let result = tensor.matmul(&tensor)?;
println!("{:?}", tensor.shape());  // OK
```

### 3. Неправильное использование Result

```rust
// ОШИБКА: Игнорирование Result
let tensor = Tensor::zeros((2, 2), DType::F32, &device);  // Возвращает Result!

// РЕШЕНИЕ: Обрабатывайте Result
let tensor = Tensor::zeros((2, 2), DType::F32, &device)?;
// или
match Tensor::zeros((2, 2), DType::F32, &device) {
    Ok(tensor) => { /* используем tensor */ }
    Err(e) => { /* обрабатываем ошибку */ }
}
```

## Заключение

Candle представляет собой мощный и эффективный фреймворк для машинного обучения в Rust экосистеме. Следование приведенным практикам обеспечивает создание robust, performant, и maintainable ML приложений, которые могут эффективно работать как в research, так и в production окружениях.

Ключевые принципы:

- **Безопасность типов** — используйте compile-time проверки
- **Производительность** — оптимизируйте операции и управление памятью
- **Модульность** — создавайте переиспользуемые компоненты
- **Тестирование** — покрывайте код comprehensive тестами
- **Интеграция** — используйте возможности Hugging Face экосистемы

Особая интеграция с Hugging Face экосистемой делает Candle идеальным выбором для разработчиков, стремящихся к высокой производительности без компромиссов в безопасности кода.
