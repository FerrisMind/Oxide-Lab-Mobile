---
description: Practical Candle ML framework guide with real-world tips and troubleshooting
alwaysApply: false
---
# Candle Practical Guide - Реальные советы и решения

## Быстрый старт проекта

### Правильная инициализация

```bash
# Создание проекта
cargo new my_app --lib
cd my_app

# Базовые зависимости
cargo add candle-core candle-nn

# Выберите ОДИН бэкенд:
# CPU с ускорением (x86)
cargo add candle-core --features mkl
# Или для macOS
cargo add candle-core --features accelerate

# GPU (CUDA)
cargo add candle-core --features cuda
cargo add cudarc
```

### Обязательные импорты в main.rs

```rust
// Для MKL (x86)
extern crate intel_mkl_src;

// Для Accelerate (macOS)
extern crate accelerate_src;

// Без этого линковка упадёт!
```

## Решение типичных ошибок

### Ошибки компиляции/линковки

```rust
// Ошибка: undefined sgemm_
// Решение: добавьте в main.rs
extern crate intel_mkl_src;

// Ошибка: LINK fatal error LNK1181
// Решение: используйте mdbook test с правильными путями
// mdbook test ... -L ...

// Ошибка: cutlass: No such file
// Решение: обновите submodules
git submodule update --init

// Ошибка: gcc-11 + nvcc parameter packs
// Решение: используйте совместимую версию GCC
env NVCC_CCBIN=/usr/lib/gcc/10/bin/gcc cargo build
```

## Работа с тензорами и устройствами

### Основные принципы

```rust
use candle_core::{Tensor, Device, DType};

// Tensor всегда принадлежит конкретному Device
let device = Device::Cpu;
let tensor = Tensor::zeros((2, 3), DType::F32, &device)?;

// .to_device() создаёт КОПИЮ - не делайте в цикле!
let gpu_device = Device::new_cuda(0)?;
let gpu_tensor = tensor.to_device(&gpu_device)?; // Копия!

// Индексирование как в PyTorch
let slice = tensor.i((.., ..4))?; // tensor[:, :4] в PyTorch
```

### Выбор типов данных

```rust
// F16 = 2× экономия памяти, но требует GPU ≥ sm_70
let f16_tensor = Tensor::zeros((1000, 1000), DType::F16, &gpu_device)?;

// F32 для CPU и совместимости
let f32_tensor = Tensor::zeros((1000, 1000), DType::F32, &device)?;
```

## Shape-валидация

### Проверка размеров

```rust
use anyhow::ensure;

// Candle НЕ проверяет размеры в compile-time
fn safe_matmul(a: &Tensor, b: &Tensor) -> Result<Tensor> {
    ensure!(a.dims()[1] == b.dims()[0], "matmul shape mismatch: {:?} @ {:?}", a.shape(), b.shape());
    a.matmul(b)
}

// Явный broadcast - "магических" broadcast'ов нет
let result = tensor.broadcast_as(target_shape)?;
```

## Управление памятью

### Эффективное использование памяти

```rust
// Градиенты хранятся отдельно в VarBuilder
// .detach() и .set_requires_grad(false) не нужны

// После forward() освобождайте промежуточные результаты
let logits = model.forward(&input)?;
// ... обработка logits
drop(logits); // или просто let _ = logits;

// Для LLM: KV-cache в Vec<Tensor>, обновляйте in-place
let mut kv_cache: Vec<Tensor> = Vec::new();
// Обновляйте существующие тензоры, не пересоздавайте
```

## Загрузка весов моделей

### Safetensors - предпочтительный формат

```rust
use candle_core::safetensors;

// Быстрее и безопаснее pytorch.bin
let tensors = safetensors::load("model.safetensors", &device)?;

// memmap2 экономит ОЗУ, но медленнее на Windows/WSL
#[cfg(target_os = "linux")]
let tensors = safetensors::MmapedFile::new("model.safetensors")?;

// Параллельное шардирование
let rank = 0; // номер GPU
let tensor_slice = tensor.slice([rank..rank+1])?;
```

## Квантизация моделей

### Поддерживаемые форматы

```rust
// Форматы llama.cpp: Q4_0, Q4_1, Q5_0, Q5_1, Q8_0
// Запуск квантизированной модели:
// cargo run --example quantized --release --features cuda -- 7b-q4_0.bin

// Квантизируйте ОДНАЖДЫ вне инференса
// Сохраняйте как .gguf и загружайте через ggml_file::load()
```

## Модули и VarBuilder

### Правильная архитектура

```rust
use candle_nn::{Module, VarBuilder, VarMap};

// Всё с forward() должно реализовать Module
struct MyModel {
    linear: Linear,
}

impl Module for MyModel {
    fn forward(&self, xs: &Tensor) -> Result<Tensor> {
        self.linear.forward(xs)
    }
}

// VarBuilder = фабрика весов, создавайте ЕДИНОЖДЫ
let vb = VarBuilder::from_varmap(&varmap, DType::F32, &device);
let model = MyModel::new(&vb)?;

// Для обучения удобнее VarMap
let mut varmap = VarMap::new();
varmap.load("model.safetensors")?;
// ... обучение
varmap.save("trained_model.safetensors")?;
```

## CUDA-ядра и оптимизация

### Кастомные CUDA-ядра

```rust
// Папка candle-kernels/ - пример flash-attn-v2
// Подключение:
// candle-flash-attn = { path = "../candle-flash-attn" }

// В Cargo.toml добавьте feature:
// [features]
// flash-attn = ["candle-flash-attn/flash-attn"]

// Регистрация ядра в lib.rs:
use cuda::Kernel;
// extern "C" fn my_kernel(...) { ... }
let kernel = Kernel::new("my_kernel", my_kernel);
```

### Оптимизация производительности

```rust
// Всегда собирайте --release (≈ 10× быстрее дебага)
// cargo build --release

// CUBLAS/CUDNN для +15-30% к матмулам
cargo add candle-core --features cudnn

// NCCL для мульти-GPU
cargo add candle-core --features nccl
let devices = Device::new_cuda(0..4)?; // 4 GPU
let split_tensors = tensor.split(4, 0)?;

// Для CPU: rayon автоматически распараллеливает при mkl
```

## Асинхронная работа

### Hugging Face Hub

```rust
use hf_hub::api::tokio::Api;

// Для веб-сервисов используйте tokio версию
let api = Api::tokio().await?;

// Синхронный Api::new() блокирует поток
// НЕ используйте в actix/axum handler'ах
```

## WASM и браузер

### Сборка для браузера

```bash
# Сборка WASM
cargo build --target wasm32-unknown-unknown --features wasm

# В index.html подключите candle.js
# <script src="candle.js"></script>
```

### Загрузка моделей в браузере

```rust
// В WASM используйте fetch() вместо randn
let response = web_sys::window()
    .unwrap()
    .fetch_with_str("model.bin")
    .await?;
let bytes = response.array_buffer().await?;
let data = js_sys::Uint8Array::new(&bytes).to_vec();
let tensor = Tensor::from_vec(data, shape, &device)?;
```

## Отладка и логирование

### Полезные команды

```bash
# Первое, что спрашивают в Issues Candle
RUST_BACKTRACE=1 cargo run ...

# Для f16 на CPU сначала приведите к f32
let debug_tensor = tensor.to_dtype(DType::F32)?;
println!("{:?}", debug_tensor);
```

## Типичные подводные камни

### Частые ошибки

```rust
// Tensor::randn требует std feature - в WASM используйте Tensor::from_vec
#[cfg(not(target_arch = "wasm32"))]
let tensor = Tensor::randn(0f32, 1f32, shape, &device)?;

// Tensor::cat по dim=0 медленнее stack
let stacked = Tensor::stack(&tensors, 0)?; // Быстрее
// let concatenated = Tensor::cat(&tensors, 0)?; // Медленнее

// view() ≠ reshape() - первый требует континуальный буфер
let contiguous = tensor.contiguous()?;
let view = contiguous.i((.., ..10))?;

// Linear ожидает weight: (out_features, in_features) - как в PyTorch
let linear = Linear::new(in_features, out_features, &device)?;

// НЕ храните Device внутри структуры модели
// Передавайте как параметр forward(&self, xs: &Tensor, device: &Device)
```

## Полезные ресурсы

### Где получить помощь

- **Issues**: https://github.com/huggingface/candle/issues (ответ в течение суток)
- **Discord**: Hugging Face → #rust-candle
- **Документация**: https://huggingface.github.io/candle/
- **Онлайн-демо**: https://huggingface.co/spaces/lmz/candle-llama2

### Тестирование окружения

```bash
# Клонируйте свежие примеры HF
git clone --depth 1 https://github.com/huggingface/candle.git
cd candle

# Запустите как "живой" тест окружения
cargo run --example quantized-qwen3 --release --features cuda -- --prompt "Hello"
```

## Лучшие практики

### 1. Всегда используйте осмысленные имена

```rust
// Плохо
let t1 = Tensor::ones((10, 20), DType::F32, &device)?;
let t2 = t1.matmul(&weights)?;

// Хорошо
let input_features = Tensor::ones((batch_size, feature_dim), DType::F32, &device)?;
let hidden_layer = input_features.matmul(&weight_matrix)?;
```

### 2. Группируйте операции на одном устройстве

```rust
// Плохо - много переносов
let cpu_tensor = Tensor::ones((2, 2), DType::F32, &Device::Cpu)?;
let gpu_tensor = cpu_tensor.to_device(&gpu_device)?;
let result = gpu_tensor.matmul(&gpu_tensor)?;
let final_result = result.to_device(&Device::Cpu)?;

// Хорошо - минимум переносов
let gpu_tensor = Tensor::ones((2, 2), DType::F32, &gpu_device)?;
let result = gpu_tensor.matmul(&gpu_tensor)?;
// Переносите только финальный результат
```

### 3. Используйте scoped блоки для управления памятью

```rust
// Автоматическое освобождение памяти
{
    let large_tensor = Tensor::randn(0f32, 1f32, (1000, 1000), &device)?;
    let result = large_tensor.matmul(&large_tensor)?;
    // Память автоматически освобождается здесь
}
```

Следуйте этим практическим советам для эффективной работы с Candle и избежания типичных проблем.
